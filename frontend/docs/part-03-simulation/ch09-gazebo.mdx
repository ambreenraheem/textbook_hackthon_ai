---
id: ch09-gazebo
title: Chapter 9 - Gazebo Simulation
description: Learn to simulate robots in Gazebo, create worlds, and integrate with ROS 2.
sidebar_label: Ch 9. Gazebo
sidebar_position: 1
keywords: [Gazebo, simulation, physics engine, URDF, SDF]
difficulty: intermediate
estimatedReadingTime: 30
---

# Chapter 9: Gazebo Simulation

## Learning Objectives

By the end of this chapter, you will be able to:
- Set up Gazebo for robot simulation
- Create robot models using URDF/SDF
- Build simulation worlds and environments
- Integrate Gazebo with ROS 2

## Introduction

Gazebo is one of the most widely used open-source robot simulators in the robotics community. Originally developed for robotics research, Gazebo provides high-fidelity physics simulation, realistic sensor simulation, and seamless integration with ROS 2. Whether you're developing a mobile robot, manipulator, or humanoid system, Gazebo offers the tools necessary to test and validate your designs before deploying to physical hardware.

The latest versions of Gazebo (Fortress, Garden, and Harmonic) represent a complete architectural overhaul from the classic Gazebo (Gazebo 11). These modern versions are built with a modular, library-based architecture called "Gazebo" (formerly "Ignition Gazebo"), offering improved performance, better plugin systems, and enhanced rendering capabilities.

### Why Use Gazebo for Robot Simulation?

**Advantages:**
- **Open-source and free**: No licensing costs, with active community support
- **Physics accuracy**: Multiple physics engines (ODE, Bullet, DART, Simbody) for different use cases
- **Sensor fidelity**: Realistic simulation of cameras, LiDAR, IMU, GPS, and contact sensors
- **ROS 2 integration**: Native support through gazebo_ros_pkgs
- **Scalability**: From simple wheeled robots to complex humanoid systems
- **Extensibility**: Plugin architecture for custom behaviors and sensors

**When to Choose Gazebo:**
- Standard robotics workflows with ROS 2
- Research and prototyping where open-source is preferred
- Mobile robots, drones, and manipulators
- Multi-robot systems and swarm robotics
- Educational environments and tutorials

## Core Architecture

### Client-Server Model

Modern Gazebo uses a client-server architecture:

```
┌─────────────────┐
│  GUI Client     │
│  (gz sim -g)    │
└────────┬────────┘
         │
         │  gRPC/Transport
         │
┌────────▼────────┐     ┌──────────────┐
│  Gazebo Server  │────▶│ Physics      │
│  (gz sim -s)    │     │ Engine       │
└────────┬────────┘     └──────────────┘
         │
         │  Plugin System
         │
┌────────▼────────┐
│  Custom Plugins │
│  ROS 2 Bridge   │
└─────────────────┘
```

**Benefits:**
- Run headless simulations on servers without GUI overhead
- Distributed simulations across multiple machines
- Better performance isolation
- Easier debugging and testing

### Physics Engines

Gazebo supports multiple physics engines, each with different characteristics:

| Engine | Strengths | Use Cases |
|--------|-----------|-----------|
| **DART** | Stable, accurate constraints | Humanoids, complex articulations |
| **Bullet** | Fast, good collision detection | Real-time applications, gaming |
| **ODE** | Lightweight, widely tested | Mobile robots, legacy support |
| **Simbody** | Biomechanics, precision | Medical robotics, human simulation |

:::tip Choosing a Physics Engine
For humanoid robots, **DART** is generally recommended due to its superior constraint solver and stability with complex joint chains. For wheeled mobile robots, **ODE** or **Bullet** provide good performance with lower computational overhead.
:::

## Installation and Setup

### Installing Gazebo Garden (Recommended for ROS 2 Humble)

```bash
# Add OSRF repository
sudo apt-get update
sudo apt-get install lsb-release wget gnupg

sudo wget https://packages.osrfoundation.org/gazebo.gpg -O /usr/share/keyrings/pkgs-osrf-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/pkgs-osrf-archive-keyring.gpg] http://packages.osrfoundation.org/gazebo/ubuntu-stable $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/gazebo-stable.list > /dev/null

# Install Gazebo Garden
sudo apt-get update
sudo apt-get install gz-garden

# Verify installation
gz sim --version
```

### Installing ROS 2 - Gazebo Integration

```bash
# Install gazebo_ros_pkgs for ROS 2 Humble
sudo apt-get install ros-humble-ros-gz

# This includes:
# - ros_gz_bridge: Message translation between ROS 2 and Gazebo
# - ros_gz_sim: Launch integration
# - ros_gz_image: Image transport
```

### Verifying Installation

```bash
# Test Gazebo standalone
gz sim shapes.sdf

# Test ROS 2 integration
ros2 launch ros_gz_sim gz_sim.launch.py gz_args:="empty.sdf"
```

## Creating Simulation Worlds

### SDF Format Basics

Gazebo uses the Simulation Description Format (SDF) for worlds and models. SDF is XML-based and more feature-rich than URDF.

**Basic World Structure:**

```xml
<?xml version="1.0"?>
<sdf version="1.9">
  <world name="humanoid_world">

    <!-- Physics Configuration -->
    <physics name="dart_physics" type="dart">
      <max_step_size>0.001</max_step_size>
      <real_time_factor>1.0</real_time_factor>
      <real_time_update_rate>1000</real_time_update_rate>
    </physics>

    <!-- Lighting -->
    <light type="directional" name="sun">
      <cast_shadows>true</cast_shadows>
      <pose>0 0 10 0 0 0</pose>
      <diffuse>0.8 0.8 0.8 1</diffuse>
      <specular>0.2 0.2 0.2 1</specular>
      <attenuation>
        <range>1000</range>
      </attenuation>
      <direction>-0.5 0.1 -0.9</direction>
    </light>

    <!-- Ground Plane -->
    <model name="ground_plane">
      <static>true</static>
      <link name="link">
        <collision name="collision">
          <geometry>
            <plane>
              <normal>0 0 1</normal>
              <size>100 100</size>
            </plane>
          </geometry>
          <surface>
            <friction>
              <ode>
                <mu>1.0</mu>
                <mu2>1.0</mu2>
              </ode>
            </friction>
          </surface>
        </collision>
        <visual name="visual">
          <geometry>
            <plane>
              <normal>0 0 1</normal>
              <size>100 100</size>
            </plane>
          </geometry>
          <material>
            <ambient>0.8 0.8 0.8 1</ambient>
            <diffuse>0.8 0.8 0.8 1</diffuse>
          </material>
        </visual>
      </link>
    </model>

    <!-- Include existing models -->
    <include>
      <uri>https://fuel.gazebosim.org/1.0/OpenRobotics/models/Construction Cone</uri>
      <pose>2 0 0 0 0 0</pose>
    </include>

  </world>
</sdf>
```

### Advanced Environment Features

**Terrain Generation:**

```xml
<model name="heightmap">
  <static>true</static>
  <link name="link">
    <collision name="collision">
      <geometry>
        <heightmap>
          <uri>file://media/materials/textures/terrain.png</uri>
          <size>50 50 10</size>
          <pos>0 0 0</pos>
        </heightmap>
      </geometry>
    </collision>
    <visual name="visual">
      <geometry>
        <heightmap>
          <texture>
            <diffuse>file://media/materials/textures/grass.jpg</diffuse>
            <normal>file://media/materials/textures/grass_normal.jpg</normal>
            <size>10</size>
          </texture>
          <uri>file://media/materials/textures/terrain.png</uri>
          <size>50 50 10</size>
        </heightmap>
      </geometry>
    </visual>
  </link>
</model>
```

## Robot Modeling with URDF and SDF

### URDF vs. SDF: When to Use Each

**URDF (Unified Robot Description Format):**
- Standard for ROS ecosystems
- Simpler, widely supported
- Limited to single robot descriptions
- Best for: Robot definitions shared between simulation and real hardware

**SDF (Simulation Description Format):**
- More expressive and flexible
- Supports worlds, multiple models, plugins
- Better physics and sensor specifications
- Best for: Simulation-specific features, complex scenes

### Converting URDF to SDF

```bash
# Command-line conversion
gz sdf -p robot.urdf > robot.sdf

# Programmatic conversion in Python
from gz.math7 import Pose3d
import sdformat13 as sdf

root = sdf.Root()
root.LoadSdfString(urdf_content)
sdf_string = root.Element().ToString("")
```

### Complete Humanoid Robot Model

**humanoid.sdf:**

```xml
<?xml version="1.0"?>
<sdf version="1.9">
  <model name="simple_humanoid">
    <pose>0 0 1.0 0 0 0</pose>

    <!-- Base Link (Torso) -->
    <link name="torso">
      <pose>0 0 0 0 0 0</pose>
      <inertial>
        <mass>10.0</mass>
        <inertia>
          <ixx>0.1</ixx>
          <iyy>0.1</iyy>
          <izz>0.1</izz>
        </inertia>
      </inertial>
      <collision name="torso_collision">
        <geometry>
          <box>
            <size>0.3 0.2 0.5</size>
          </box>
        </geometry>
      </collision>
      <visual name="torso_visual">
        <geometry>
          <box>
            <size>0.3 0.2 0.5</size>
          </box>
        </geometry>
        <material>
          <ambient>0.2 0.2 0.8 1</ambient>
          <diffuse>0.2 0.2 0.8 1</diffuse>
        </material>
      </visual>

      <!-- IMU Sensor -->
      <sensor name="imu_sensor" type="imu">
        <always_on>1</always_on>
        <update_rate>100</update_rate>
        <imu>
          <angular_velocity>
            <x>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>2e-4</stddev>
              </noise>
            </x>
            <y>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>2e-4</stddev>
              </noise>
            </y>
            <z>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>2e-4</stddev>
              </noise>
            </z>
          </angular_velocity>
          <linear_acceleration>
            <x>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>1.7e-2</stddev>
              </noise>
            </x>
            <y>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>1.7e-2</stddev>
              </noise>
            </y>
            <z>
              <noise type="gaussian">
                <mean>0.0</mean>
                <stddev>1.7e-2</stddev>
              </noise>
            </z>
          </linear_acceleration>
        </imu>
      </sensor>
    </link>

    <!-- Right Hip Joint and Link -->
    <joint name="right_hip_joint" type="revolute">
      <parent>torso</parent>
      <child>right_thigh</child>
      <pose>0 0 0 0 0 0</pose>
      <axis>
        <xyz>0 1 0</xyz>
        <limit>
          <lower>-1.57</lower>
          <upper>1.57</upper>
          <effort>100</effort>
          <velocity>10</velocity>
        </limit>
        <dynamics>
          <damping>0.5</damping>
          <friction>0.1</friction>
        </dynamics>
      </axis>
    </joint>

    <link name="right_thigh">
      <pose relative_to="right_hip_joint">0 -0.15 -0.3 0 0 0</pose>
      <inertial>
        <mass>5.0</mass>
        <inertia>
          <ixx>0.05</ixx>
          <iyy>0.05</iyy>
          <izz>0.01</izz>
        </inertia>
      </inertial>
      <collision name="right_thigh_collision">
        <geometry>
          <cylinder>
            <radius>0.06</radius>
            <length>0.4</length>
          </cylinder>
        </geometry>
      </collision>
      <visual name="right_thigh_visual">
        <geometry>
          <cylinder>
            <radius>0.06</radius>
            <length>0.4</length>
          </cylinder>
        </geometry>
        <material>
          <ambient>0.8 0.2 0.2 1</ambient>
          <diffuse>0.8 0.2 0.2 1</diffuse>
        </material>
      </visual>
    </link>

    <!-- Joint State Publisher Plugin -->
    <plugin
      filename="gz-sim-joint-state-publisher-system"
      name="gz::sim::systems::JointStatePublisher">
    </plugin>

    <!-- Apply force/torque plugin for control -->
    <plugin
      filename="gz-sim-apply-joint-force-system"
      name="gz::sim::systems::ApplyJointForce">
    </plugin>

  </model>
</sdf>
```

## Sensor Simulation

### Camera Sensors

```xml
<sensor name="camera" type="camera">
  <pose>0.2 0 0.1 0 0 0</pose>
  <camera>
    <horizontal_fov>1.047</horizontal_fov>
    <image>
      <width>640</width>
      <height>480</height>
      <format>R8G8B8</format>
    </image>
    <clip>
      <near>0.1</near>
      <far>100</far>
    </clip>
    <noise>
      <type>gaussian</type>
      <mean>0.0</mean>
      <stddev>0.007</stddev>
    </noise>
  </camera>
  <always_on>1</always_on>
  <update_rate>30</update_rate>
  <visualize>true</visualize>
  <topic>/camera/image_raw</topic>
</sensor>
```

### Depth Camera

```xml
<sensor name="depth_camera" type="depth_camera">
  <pose>0.2 0 0.1 0 0 0</pose>
  <camera>
    <horizontal_fov>1.047</horizontal_fov>
    <image>
      <width>640</width>
      <height>480</height>
      <format>R_FLOAT32</format>
    </image>
    <clip>
      <near>0.1</near>
      <far>10.0</far>
    </clip>
  </camera>
  <always_on>1</always_on>
  <update_rate>30</update_rate>
  <topic>/depth_camera</topic>
</sensor>
```

### LiDAR Sensor

```xml
<sensor name="lidar" type="gpu_lidar">
  <pose>0 0 0.3 0 0 0</pose>
  <lidar>
    <scan>
      <horizontal>
        <samples>640</samples>
        <resolution>1</resolution>
        <min_angle>-2.094</min_angle>
        <max_angle>2.094</max_angle>
      </horizontal>
      <vertical>
        <samples>16</samples>
        <resolution>1</resolution>
        <min_angle>-0.261799</min_angle>
        <max_angle>0.261799</max_angle>
      </vertical>
    </scan>
    <range>
      <min>0.1</min>
      <max>30.0</max>
      <resolution>0.01</resolution>
    </range>
    <noise>
      <type>gaussian</type>
      <mean>0.0</mean>
      <stddev>0.01</stddev>
    </noise>
  </lidar>
  <always_on>1</always_on>
  <update_rate>10</update_rate>
  <topic>/lidar/points</topic>
</sensor>
```

### Contact/Force Sensors

```xml
<sensor name="foot_contact" type="contact">
  <contact>
    <collision>foot_collision</collision>
  </contact>
  <always_on>1</always_on>
  <update_rate>100</update_rate>
  <topic>/foot/contact</topic>
</sensor>
```

## ROS 2 Integration

### Launching Gazebo with ROS 2

**gazebo_launch.py:**

```python
from launch import LaunchDescription
from launch.actions import IncludeLaunchDescription, DeclareLaunchArgument
from launch.launch_description_sources import PythonLaunchDescriptionSource
from launch.substitutions import LaunchConfiguration, PathJoinSubstitution
from launch_ros.actions import Node
from launch_ros.substitutions import FindPackageShare

def generate_launch_description():
    # Paths
    pkg_ros_gz_sim = FindPackageShare('ros_gz_sim')
    pkg_humanoid_sim = FindPackageShare('humanoid_simulation')

    # World file
    world_file = PathJoinSubstitution([
        pkg_humanoid_sim,
        'worlds',
        'humanoid_world.sdf'
    ])

    # Launch Gazebo
    gz_sim = IncludeLaunchDescription(
        PythonLaunchDescriptionSource([
            PathJoinSubstitution([
                pkg_ros_gz_sim,
                'launch',
                'gz_sim.launch.py'
            ])
        ]),
        launch_arguments={
            'gz_args': [world_file, ' -r'],
            'on_exit_shutdown': 'true'
        }.items()
    )

    # ROS-Gazebo bridge for topics
    bridge_params = [
        {'topic_name': '/imu',
         'ros_type_name': 'sensor_msgs/msg/Imu',
         'gz_type_name': 'gz.msgs.IMU'},
        {'topic_name': '/camera/image_raw',
         'ros_type_name': 'sensor_msgs/msg/Image',
         'gz_type_name': 'gz.msgs.Image'},
        {'topic_name': '/lidar/points',
         'ros_type_name': 'sensor_msgs/msg/PointCloud2',
         'gz_type_name': 'gz.msgs.PointCloudPacked'},
        {'topic_name': '/joint_states',
         'ros_type_name': 'sensor_msgs/msg/JointState',
         'gz_type_name': 'gz.msgs.Model'},
    ]

    ros_gz_bridge = Node(
        package='ros_gz_bridge',
        executable='parameter_bridge',
        arguments=[
            f"{topic['topic_name']}@{topic['ros_type_name']}@{topic['gz_type_name']}"
            for topic in bridge_params
        ],
        output='screen'
    )

    # Spawn robot
    spawn_robot = Node(
        package='ros_gz_sim',
        executable='create',
        arguments=[
            '-name', 'humanoid',
            '-file', PathJoinSubstitution([
                pkg_humanoid_sim,
                'models',
                'humanoid.sdf'
            ]),
            '-x', '0',
            '-y', '0',
            '-z', '1.0'
        ],
        output='screen'
    )

    return LaunchDescription([
        gz_sim,
        ros_gz_bridge,
        spawn_robot
    ])
```

### Message Bridging

**Creating Custom Message Bridges:**

```python
# Bridge custom messages
from ros_gz_bridge.mappings import Mapping

# Define mapping
custom_mapping = Mapping(
    ros_type='custom_msgs/msg/HumanoidState',
    gz_type='gz.msgs.Custom',
    direction=Mapping.BIDIRECTIONAL
)
```

### Control Interface

**ROS 2 Joint Control with Gazebo:**

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import Float64MultiArray
from sensor_msgs.msg import JointState

class HumanoidController(Node):
    def __init__(self):
        super().__init__('humanoid_controller')

        # Publisher for joint commands
        self.joint_cmd_pub = self.create_publisher(
            Float64MultiArray,
            '/humanoid/joint_commands',
            10
        )

        # Subscriber for joint states
        self.joint_state_sub = self.create_subscription(
            JointState,
            '/joint_states',
            self.joint_state_callback,
            10
        )

        # Control timer (100 Hz)
        self.timer = self.create_timer(0.01, self.control_loop)
        self.current_joint_states = None

    def joint_state_callback(self, msg):
        self.current_joint_states = msg

    def control_loop(self):
        if self.current_joint_states is None:
            return

        # Simple PD controller
        cmd = Float64MultiArray()

        # Target positions (standing pose)
        target_positions = [0.0, 0.0, -0.5, 1.0, -0.5, 0.0]  # Hip, knee angles

        kp = 100.0  # Proportional gain
        kd = 10.0   # Derivative gain

        for i, (target, current_pos, current_vel) in enumerate(
            zip(target_positions,
                self.current_joint_states.position,
                self.current_joint_states.velocity)
        ):
            error = target - current_pos
            torque = kp * error - kd * current_vel
            cmd.data.append(torque)

        self.joint_cmd_pub.publish(cmd)

def main():
    rclpy.init()
    controller = HumanoidController()
    rclpy.spin(controller)
    controller.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

## Plugin Development

### Custom Gazebo Plugins

Plugins extend Gazebo's functionality. There are several types:

- **System plugins**: Global simulation features
- **Model plugins**: Per-model behaviors
- **Sensor plugins**: Custom sensor processing
- **Visual plugins**: Rendering and GUI extensions

**Example: Balance Controller Plugin**

```cpp
#include <gz/sim/System.hh>
#include <gz/sim/Model.hh>
#include <gz/sim/components/JointPosition.hh>
#include <gz/sim/components/JointVelocity.hh>
#include <gz/sim/components/JointForceCmd.hh>
#include <gz/sim/components/Pose.hh>

namespace humanoid_plugins
{
  class BalanceController
    : public gz::sim::System,
      public gz::sim::ISystemConfigure,
      public gz::sim::ISystemPreUpdate
  {
    public: void Configure(
      const gz::sim::Entity &_entity,
      const std::shared_ptr<const sdf::Element> &_sdf,
      gz::sim::EntityComponentManager &_ecm,
      gz::sim::EventManager &/*_eventMgr*/) override
    {
      this->model = gz::sim::Model(_entity);

      // Get parameters from SDF
      if (_sdf->HasElement("kp"))
        this->kp = _sdf->Get<double>("kp");

      // Find joints
      this->hipJoint = this->model.JointByName(_ecm, "hip_joint");
      this->kneeJoint = this->model.JointByName(_ecm, "knee_joint");
    }

    public: void PreUpdate(
      const gz::sim::UpdateInfo &_info,
      gz::sim::EntityComponentManager &_ecm) override
    {
      // Get current pose
      auto poseComp = _ecm.Component<gz::sim::components::Pose>(
        this->model.Entity());
      auto pose = poseComp->Data();

      // Calculate tilt
      double tilt = pose.Rot().Pitch();

      // Simple balance control
      double hipTorque = -this->kp * tilt;

      // Apply torques
      _ecm.SetComponentData<gz::sim::components::JointForceCmd>(
        this->hipJoint, {hipTorque});
    }

    private: gz::sim::Model model;
    private: gz::sim::Entity hipJoint;
    private: gz::sim::Entity kneeJoint;
    private: double kp = 100.0;
  };
}

// Register plugin
#include <gz/plugin/Register.hh>
GZ_ADD_PLUGIN(
  humanoid_plugins::BalanceController,
  gz::sim::System,
  humanoid_plugins::BalanceController::ISystemConfigure,
  humanoid_plugins::BalanceController::ISystemPreUpdate)
```

**CMakeLists.txt for Plugin:**

```cmake
cmake_minimum_required(VERSION 3.10)
project(humanoid_plugins)

find_package(gz-cmake3 REQUIRED)
find_package(gz-sim7 REQUIRED)

add_library(BalanceController SHARED BalanceController.cpp)
target_link_libraries(BalanceController
  gz-sim7::gz-sim7
)

install(TARGETS BalanceController
  DESTINATION lib
)
```

## Physics Tuning and Performance

### Optimizing Physics Parameters

```xml
<physics name="dart_physics" type="dart">
  <!-- Time step: smaller = more accurate, slower -->
  <max_step_size>0.001</max_step_size>

  <!-- Real-time factor: 1.0 = real-time, >1 = faster -->
  <real_time_factor>1.0</real_time_factor>

  <!-- Update rate -->
  <real_time_update_rate>1000</real_time_update_rate>

  <!-- Solver parameters -->
  <dart>
    <solver>
      <solver_type>dantzig</solver_type>
    </solver>
    <collision_detector>bullet</collision_detector>
  </dart>
</physics>
```

:::warning Physics Stability
For humanoid robots with many degrees of freedom, use smaller time steps (0.001s or less) to maintain stability. This comes at a computational cost, so profile your simulation to find the right balance.
:::

### Contact Surface Tuning

```xml
<surface>
  <contact>
    <collide_bitmask>0x01</collide_bitmask>
    <ode>
      <kp>1000000.0</kp>  <!-- Contact stiffness -->
      <kd>100.0</kd>      <!-- Contact damping -->
      <max_vel>0.01</max_vel>
      <min_depth>0.001</min_depth>
    </ode>
  </contact>
  <friction>
    <ode>
      <mu>1.0</mu>      <!-- Coefficient of friction -->
      <mu2>1.0</mu2>    <!-- Secondary friction direction -->
      <slip1>0.0</slip1>
      <slip2>0.0</slip2>
    </ode>
  </friction>
</surface>
```

## Best Practices

### Model Design

1. **Inertia Accuracy**: Calculate proper inertial properties
   ```python
   # Use MeshLab or similar tools to compute inertia tensors
   # For simple shapes:
   # Box: I_xx = m/12 * (h² + d²)
   # Cylinder: I_xx = m/12 * (3r² + h²)
   ```

2. **Collision Simplification**: Use simple collision geometries
   - Visual: High-detail mesh
   - Collision: Simplified primitives (boxes, cylinders, spheres)

3. **Joint Limits**: Always specify realistic limits
   ```xml
   <limit>
     <lower>-1.57</lower>
     <upper>1.57</upper>
     <effort>100</effort>
     <velocity>10</velocity>
   </limit>
   ```

### Performance Optimization

**Techniques:**

1. **Use GPU-accelerated sensors** when available
   ```xml
   <sensor type="gpu_lidar">  <!-- Instead of 'lidar' -->
   ```

2. **Reduce update rates** for non-critical sensors
   ```xml
   <update_rate>10</update_rate>  <!-- Instead of 30 Hz for cameras -->
   ```

3. **Run headless** for batch simulations
   ```bash
   gz sim -s world.sdf  # Server only, no GUI
   ```

4. **Use level of detail (LOD)** for visual meshes
   ```xml
   <visual>
     <geometry>
       <mesh>
         <uri>model://robot/meshes/link_lod0.dae</uri>
       </mesh>
     </geometry>
   </visual>
   ```

## Common Pitfalls

### 1. Model Exploding or Unstable

**Symptoms:** Robot flies apart, joints behave erratically

**Solutions:**
- Check mass and inertia values (must be positive and realistic)
- Reduce time step size
- Add joint damping
- Verify collision geometries don't intersect initially

```xml
<dynamics>
  <damping>1.0</damping>  <!-- Add damping -->
  <friction>0.1</friction>
</dynamics>
```

### 2. Slow Simulation

**Symptoms:** Real-time factor `<< 1.0`

**Solutions:**
- Simplify collision meshes
- Reduce sensor update rates
- Use faster physics engine (Bullet instead of DART)
- Disable shadows and reduce visual quality

### 3. Sensors Not Publishing

**Symptoms:** No data on sensor topics

**Solutions:**
- Verify topic names match between SDF and ROS 2 bridge
- Check `always_on` is set to true
- Ensure sensor plugin is loaded
- Use `gz topic -l` to see available Gazebo topics

```bash
# Debug sensor topics
gz topic -l
gz topic -e -t /camera/image_raw
```

### 4. Joint Control Not Working

**Symptoms:** Commanded torques have no effect

**Solutions:**
- Add `ApplyJointForce` plugin to model
- Verify joint names match in control code
- Check effort limits in joint definitions
- Ensure physics engine supports force commands

## Complete Example: Bipedal Walking Simulation

**Project Structure:**
```
humanoid_gazebo/
├── models/
│   └── biped/
│       ├── model.sdf
│       └── meshes/
├── worlds/
│   └── walking_test.sdf
├── launch/
│   └── walking_sim.launch.py
└── config/
    └── controllers.yaml
```

**Walking Controller:**

```python
import rclpy
from rclpy.node import Node
import numpy as np
from sensor_msgs.msg import JointState
from std_msgs.msg import Float64MultiArray

class WalkingController(Node):
    def __init__(self):
        super().__init__('walking_controller')

        self.joint_cmd_pub = self.create_publisher(
            Float64MultiArray, '/joint_commands', 10)
        self.joint_state_sub = self.create_subscription(
            JointState, '/joint_states', self.joint_callback, 10)

        self.timer = self.create_timer(0.01, self.control_step)

        # Walking parameters
        self.phase = 0.0
        self.step_frequency = 1.0  # Hz
        self.step_height = 0.05    # meters

        self.joints = None

    def joint_callback(self, msg):
        self.joints = msg

    def inverse_kinematics_leg(self, foot_pos):
        """Simple 2D IK for leg (hip, knee)"""
        x, z = foot_pos
        l1 = 0.4  # Thigh length
        l2 = 0.4  # Shin length

        # Law of cosines
        d = np.sqrt(x**2 + z**2)
        d = np.clip(d, 0.01, l1 + l2 - 0.01)

        knee = np.arccos((l1**2 + l2**2 - d**2) / (2 * l1 * l2))
        alpha = np.arctan2(x, -z)
        beta = np.arccos((l1**2 + d**2 - l2**2) / (2 * l1 * d))
        hip = alpha - beta

        return hip, knee

    def control_step(self):
        if self.joints is None:
            return

        # Update phase
        dt = 0.01
        self.phase += 2 * np.pi * self.step_frequency * dt
        if self.phase > 2 * np.pi:
            self.phase -= 2 * np.pi

        # Generate foot trajectories
        if self.phase < np.pi:  # Right leg stance, left leg swing
            right_z = -0.7
            left_z = -0.7 + self.step_height * np.sin(self.phase)
        else:  # Left leg stance, right leg swing
            left_z = -0.7
            right_z = -0.7 + self.step_height * np.sin(self.phase - np.pi)

        # IK to joint angles
        right_hip, right_knee = self.inverse_kinematics_leg([0.0, right_z])
        left_hip, left_knee = self.inverse_kinematics_leg([0.0, left_z])

        # PD control
        kp = 100.0
        kd = 10.0

        targets = [right_hip, right_knee, left_hip, left_knee]
        torques = []

        for i, target in enumerate(targets):
            error = target - self.joints.position[i]
            torque = kp * error - kd * self.joints.velocity[i]
            torques.append(np.clip(torque, -100, 100))

        # Publish
        msg = Float64MultiArray()
        msg.data = torques
        self.joint_cmd_pub.publish(msg)

def main():
    rclpy.init()
    controller = WalkingController()
    rclpy.spin(controller)
    rclpy.shutdown()
```

## Practice Exercises

### Exercise 1: Custom World Creation

**Task:** Create a challenging environment for humanoid navigation

**Requirements:**
- Stairs (3 steps, 15cm height each)
- Ramp (30-degree incline)
- Obstacles (boxes, cylinders)
- Proper lighting and textures

**Validation:**
- Load world in Gazebo without errors
- Robot can spawn and interact with environment
- Contact forces realistic on stairs

### Exercise 2: Multi-Sensor Integration

**Task:** Add complete sensor suite to humanoid

**Sensors to add:**
- RGB-D camera (head)
- 2D LiDAR (torso)
- IMU (torso)
- Force sensors (both feet)
- Joint encoders

**Validation:**
- All sensors publish to correct ROS 2 topics
- Visualize in RViz2
- Record rosbag and verify data integrity

### Exercise 3: Balance Controller

**Task:** Implement active balance using IMU feedback

**Requirements:**
- Read IMU orientation
- Calculate center of mass offset
- Apply corrective ankle/hip torques
- Maintain upright pose on uneven terrain

**Validation:**
- Robot maintains balance for 60 seconds
- Withstands external pushes (applied forces)
- Works on 10-degree tilted surface

## Further Reading

**Official Documentation:**
- [Gazebo Documentation](https://gazebosim.org/docs)
- [SDF Specification](http://sdformat.org/)
- [ROS 2 - Gazebo Integration](https://github.com/gazebosim/ros_gz)

**Tutorials:**
- [Building Robot Simulations](https://gazebosim.org/docs/garden/building_robot)
- [Sensor Simulation](https://gazebosim.org/docs/garden/sensors)
- [Plugin Development](https://gazebosim.org/docs/garden/tutorials)

**Research Papers:**
- "Gazebo: A Multi-Robot Simulator" (Koenig & Howard, 2004)
- "Design and Use Paradigms for Gazebo" (Koenig et al., 2004)

## Cross-References

- **Chapter 3**: Understanding URDF models before converting to SDF
- **Chapter 7**: ROS 2 control interfaces used with Gazebo
- **Chapter 10**: Comparing with Unity simulation capabilities
- **Chapter 11**: Comparing with NVIDIA Isaac Sim for photorealism
- **Chapter 15**: Sim-to-real transfer considerations
- **Chapter 21**: Hardware-in-the-loop testing with Gazebo

## Next Steps

After mastering Gazebo, you should:

1. **Explore Unity for Robotics** (Chapter 10) for better graphics and ML integration
2. **Learn NVIDIA Isaac Sim** (Chapter 11) for photorealistic simulation
3. **Study sim-to-real transfer** (Chapter 15) to deploy controllers on real hardware
4. **Implement advanced controllers** using reinforcement learning (Chapter 18)
5. **Develop multi-robot scenarios** for swarm and collaborative behaviors

**Recommended Projects:**
- Full walking gait implementation with trajectory optimization
- Vision-based navigation in Gazebo environments
- Multi-robot coordination (2+ humanoids)
- Manipulation tasks (picking/placing objects)
- Integration with MoveIt 2 for motion planning

:::tip Next Chapter Preview
In Chapter 10, we'll explore **Unity for Robotics**, which offers superior graphics, easier environment creation, and powerful machine learning integration through ML-Agents. You'll learn when to choose Unity over Gazebo and how to leverage both simulators effectively.
:::
